{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase-1 code starter template\n",
        "### The below code is for your reference; please feel free to change it partially or fully.\n",
        "### Please make sure it does not have any bugs or mistakes. Code authors DO NOT claim the code is bug-free. It is the student's responsibility to ensure its correctness.\n",
        "## In all cases you must use a base model which consist of:\n",
        "- 1 convulosion layer with 16 channels, 3x3 kernel, and a relu activation.\n",
        "- Fully connected layer with 2 neurons and a relu activation.\n",
        "- Fully connected layer with num_classes neurons and a softmax activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CP4ljRrIt4g",
        "outputId": "0e5cf3f9-9a65-4bc9-b121-226ebc8b5210"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "your tensorflow version is 2.15.0. It is advised to use tensorflow 2.15.0 to avoid any errors.\n",
            "Using device: GPU\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "print(f'your tensorflow version is {tf.__version__}. It is advised to use tensorflow 2.15.0 to avoid any errors.')\n",
        "assert tf.__version__=='2.15.0', 'WARNING!!! different TensorFlow version may produce an error while quantizing.\\nTo proceed, comment this line.'\n",
        "\n",
        "\n",
        "# --- Device Detection ---\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "device = '/GPU:0' if gpus else '/CPU:0'\n",
        "dev_name = 'GPU' if gpus else 'CPU'\n",
        "print(f\"Using device: {dev_name}\")\n",
        "\n",
        "# --- Functions ---\n",
        "\n",
        "def create_base_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(2, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def prepare_dataset(dataset_name):\n",
        "    if dataset_name == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        x_train = x_train[..., np.newaxis]\n",
        "        x_test = x_test[..., np.newaxis]\n",
        "        input_shape = (28, 28, 1)\n",
        "    elif dataset_name == 'cifar10':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        input_shape = (32, 32, 3)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    y_train = to_categorical(y_train, 10)\n",
        "    y_test = to_categorical(y_test, 10)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), input_shape, 10\n",
        "\n",
        "def evaluate_model(model, x_test, y_test):\n",
        "    start = time.time()\n",
        "    loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "    elapsed = time.time() - start\n",
        "    return acc, elapsed\n",
        "\n",
        "def profile_workload(model, image, iterations=30):\n",
        "    print(f\"Profiling {dev_name}...\")\n",
        "    latencies = []\n",
        "\n",
        "    for _ in tqdm(range(10), desc=\"Warm-up\"):\n",
        "        _ = model(image, training=False)\n",
        "\n",
        "    for _ in tqdm(range(iterations), desc=\"Profiling\"):\n",
        "        start = time.time()\n",
        "        _ = model(image, training=False)\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "    return np.mean(latencies)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase-3 code starter template\n",
        "### The below code is for your reference; please feel free to change it partially or fully.\n",
        "### Please make sure it does not have any bugs or mistakes. Code authors DO NOT claim the code is bug-free. It is the student's responsibility to ensure its correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Processing fashion_mnist...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-29 02:26:30.763792: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Pro\n",
            "2025-04-29 02:26:30.763815: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
            "2025-04-29 02:26:30.763820: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
            "2025-04-29 02:26:30.763846: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2025-04-29 02:26:30.763859: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  8/750 [..............................] - ETA: 6s - loss: 2.2923 - accuracy: 0.1133  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-29 02:26:31.066877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "750/750 [==============================] - 7s 9ms/step - loss: 1.5116 - accuracy: 0.3882 - val_loss: 1.1345 - val_accuracy: 0.5343\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 1.0633 - accuracy: 0.5718 - val_loss: 1.0167 - val_accuracy: 0.5843\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.9987 - accuracy: 0.5934 - val_loss: 0.9772 - val_accuracy: 0.5990\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.9637 - accuracy: 0.5996 - val_loss: 0.9404 - val_accuracy: 0.6247\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.9365 - accuracy: 0.6092 - val_loss: 0.9380 - val_accuracy: 0.6096\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.9240 - accuracy: 0.6137 - val_loss: 0.9425 - val_accuracy: 0.6190\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.9061 - accuracy: 0.6311 - val_loss: 0.9235 - val_accuracy: 0.6225\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 6s 9ms/step - loss: 0.8977 - accuracy: 0.6337 - val_loss: 0.9050 - val_accuracy: 0.6411\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.8926 - accuracy: 0.6352 - val_loss: 0.9000 - val_accuracy: 0.6299\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 6s 8ms/step - loss: 0.8856 - accuracy: 0.6423 - val_loss: 0.8879 - val_accuracy: 0.6538\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alshammf/anaconda3/envs/TensorFlow/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profiling GPU...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warm-up: 100%|██████████| 10/10 [00:00<00:00, 254.08it/s]\n",
            "Profiling: 100%|██████████| 30/30 [00:00<00:00, 1059.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmprwfcgil1/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmprwfcgil1/assets\n",
            "/Users/alshammf/anaconda3/envs/TensorFlow/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "2025-04-29 02:27:36.095500: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2025-04-29 02:27:36.095518: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2025-04-29 02:27:36.095736: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmprwfcgil1\n",
            "2025-04-29 02:27:36.096327: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2025-04-29 02:27:36.096332: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmprwfcgil1\n",
            "2025-04-29 02:27:36.097489: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:388] MLIR V1 optimization pass is not enabled\n",
            "2025-04-29 02:27:36.098121: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2025-04-29 02:27:36.122252: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmprwfcgil1\n",
            "2025-04-29 02:27:36.129324: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 33588 microseconds.\n",
            "2025-04-29 02:27:36.137140: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
            " * 7 ARITH ops\n",
            "\n",
            "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 1)\n",
            "  (f32: 2)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved INT8 model at fashion_mnist_base_int8.tflite\n",
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpznlw05_c/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpznlw05_c/assets\n",
            "2025-04-29 02:27:36.518261: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2025-04-29 02:27:36.518271: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2025-04-29 02:27:36.518377: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpznlw05_c\n",
            "2025-04-29 02:27:36.518982: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2025-04-29 02:27:36.518987: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpznlw05_c\n",
            "2025-04-29 02:27:36.520575: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2025-04-29 02:27:36.545729: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpznlw05_c\n",
            "2025-04-29 02:27:36.552920: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34537 microseconds.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 7, Total Ops 22, % non-converted = 31.82 %\n",
            " * 7 ARITH ops\n",
            "\n",
            "- arith.constant:    7 occurrences  (f16: 6, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 1)\n",
            "  (f32: 6)\n",
            "  (f32: 2)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved FP16 model at fashion_mnist_base_fp16.tflite\n",
            "\n",
            "Summary:\n",
            "Metric                         Base Model           Enhanced Model\n",
            "--------------------------------------------------------------------------------\n",
            "Parameters                     5600                 deleted\n",
            "Accuracy FP32 (%)              65.06%             deleted%\n",
            "Accuracy FP16 (%)              21.22%             deleted%\n",
            "Accuracy INT8 (%)              13.28%             deleted%\n",
            "Latency FP32 (ms)              0.94               deleted\n",
            "Latency FP16 (ms)              0.01               deleted\n",
            "Latency INT8 (ms)              0.01               deleted\n",
            "Size FP32 (KB)                 100.20               deleted\n",
            "Size FP16 (KB)                 14.45               deleted\n",
            "Size INT8 (KB)                 9.02               deleted\n",
            "\n",
            "Processing cifar10...\n",
            "Epoch 1/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.4394 - accuracy: 0.1052 - val_loss: 2.2936 - val_accuracy: 0.1356\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2914 - accuracy: 0.1347 - val_loss: 2.2898 - val_accuracy: 0.1419\n",
            "Epoch 3/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 2.2880 - accuracy: 0.1356 - val_loss: 2.2859 - val_accuracy: 0.1425\n",
            "Epoch 4/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2847 - accuracy: 0.1389 - val_loss: 2.2827 - val_accuracy: 0.1432\n",
            "Epoch 5/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2816 - accuracy: 0.1423 - val_loss: 2.2789 - val_accuracy: 0.1490\n",
            "Epoch 6/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2787 - accuracy: 0.1418 - val_loss: 2.2769 - val_accuracy: 0.1509\n",
            "Epoch 7/10\n",
            "625/625 [==============================] - 6s 10ms/step - loss: 2.2761 - accuracy: 0.1434 - val_loss: 2.2745 - val_accuracy: 0.1459\n",
            "Epoch 8/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2739 - accuracy: 0.1443 - val_loss: 2.2708 - val_accuracy: 0.1517\n",
            "Epoch 9/10\n",
            "625/625 [==============================] - 6s 9ms/step - loss: 2.2717 - accuracy: 0.1459 - val_loss: 2.2695 - val_accuracy: 0.1551\n",
            "Epoch 10/10\n",
            "625/625 [==============================] - 5s 9ms/step - loss: 2.2699 - accuracy: 0.1468 - val_loss: 2.2676 - val_accuracy: 0.1584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/alshammf/anaconda3/envs/TensorFlow/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Profiling GPU...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warm-up: 100%|██████████| 10/10 [00:00<00:00, 498.01it/s]\n",
            "Profiling: 100%|██████████| 30/30 [00:00<00:00, 1044.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpswwv3wbd/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpswwv3wbd/assets\n",
            "/Users/alshammf/anaconda3/envs/TensorFlow/lib/python3.9/site-packages/tensorflow/lite/python/convert.py:953: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
            "  warnings.warn(\n",
            "2025-04-29 02:28:37.088910: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2025-04-29 02:28:37.088922: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2025-04-29 02:28:37.089111: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpswwv3wbd\n",
            "2025-04-29 02:28:37.089716: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2025-04-29 02:28:37.089721: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpswwv3wbd\n",
            "2025-04-29 02:28:37.091419: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2025-04-29 02:28:37.116019: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpswwv3wbd\n",
            "2025-04-29 02:28:37.123486: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 34374 microseconds.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 7, Total Ops 16, % non-converted = 43.75 %\n",
            " * 7 ARITH ops\n",
            "\n",
            "- arith.constant:    7 occurrences  (f32: 6, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 1)\n",
            "  (f32: 2)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "fully_quantize: 0, inference_type: 6, input_inference_type: INT8, output_inference_type: INT8\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved INT8 model at cifar10_base_int8.tflite\n",
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpv_qb4yow/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpv_qb4yow/assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved FP16 model at cifar10_base_fp16.tflite\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-29 02:28:37.754970: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2025-04-29 02:28:37.754981: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2025-04-29 02:28:37.755099: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpv_qb4yow\n",
            "2025-04-29 02:28:37.755667: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2025-04-29 02:28:37.755672: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpv_qb4yow\n",
            "2025-04-29 02:28:37.757296: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2025-04-29 02:28:37.782877: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/7f/r2ps86p562s640d2zx6tvwm40000gq/T/tmpv_qb4yow\n",
            "2025-04-29 02:28:37.790694: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 35594 microseconds.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 7, Total Ops 22, % non-converted = 31.82 %\n",
            " * 7 ARITH ops\n",
            "\n",
            "- arith.constant:    7 occurrences  (f16: 6, i32: 1)\n",
            "\n",
            "\n",
            "\n",
            "  (f32: 1)\n",
            "  (f32: 6)\n",
            "  (f32: 2)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 1)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Summary:\n",
            "Metric                         Base Model           Enhanced Model\n",
            "--------------------------------------------------------------------------------\n",
            "Parameters                     7680                 deleted\n",
            "Accuracy FP32 (%)              15.98%             deleted%\n",
            "Accuracy FP16 (%)              10.00%             deleted%\n",
            "Accuracy INT8 (%)              10.00%             deleted%\n",
            "Latency FP32 (ms)              0.95               deleted\n",
            "Latency FP16 (ms)              0.02               deleted\n",
            "Latency INT8 (ms)              0.04               deleted\n",
            "Size FP32 (KB)                 123.20               deleted\n",
            "Size FP16 (KB)                 18.60               deleted\n",
            "Size INT8 (KB)                 11.10               deleted\n"
          ]
        }
      ],
      "source": [
        "def profile_tflite_model(interpreter, input_tensor, iterations=30):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    latencies = []\n",
        "\n",
        "    for _ in range(10):\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "        interpreter.invoke()\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        start = time.time()\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "        interpreter.invoke()\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "    return np.mean(latencies)\n",
        "\n",
        "def quantize_model_to_int8(model, rep_data_gen, save_path):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = rep_data_gen\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "    tflite_model = converter.convert()\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Saved INT8 model at {save_path}\")\n",
        "\n",
        "def quantize_model_to_fp16(model, save_path):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "    tflite_model = converter.convert()\n",
        "    with open(save_path, 'wb') as f:\n",
        "        f.write(tflite_model)\n",
        "    print(f\"Saved FP16 model at {save_path}\")\n",
        "\n",
        "def evaluate_tflite_accuracy(interpreter, x_test, y_test, quantized=False):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    correct = 0\n",
        "    total = x_test.shape[0]\n",
        "\n",
        "    for i in range(total):\n",
        "        input_data = x_test[i:i+1]\n",
        "        if quantized:\n",
        "            input_data = np.round(input_data * 255).astype(np.int8)\n",
        "        else:\n",
        "            input_data = input_data.astype(np.float32)\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        if np.argmax(output) == np.argmax(y_test[i]):\n",
        "            correct += 1\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    return os.path.getsize(file_path) / 1024  # in KB\n",
        "\n",
        "# --- Main Loop ---\n",
        "\n",
        "datasets = ['fashion_mnist', 'cifar10']\n",
        "EPOCHS = 10\n",
        "USE_PRETRAINED_MODELS = False # use the model you already trained in previous runs if set to True\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(f\"\\nProcessing {dataset}...\")\n",
        "\n",
        "    base_path = f\"{dataset}_base_model.h5\"\n",
        "    int8_base_path = f\"{dataset}_base_int8.tflite\"\n",
        "    fp16_base_path = f\"{dataset}_base_fp16.tflite\"\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test), input_shape, num_classes = prepare_dataset(dataset)\n",
        "\n",
        "    if os.path.exists(base_path) and USE_PRETRAINED_MODELS:\n",
        "        model_base = models.load_model(base_path)\n",
        "    else:\n",
        "        model_base = create_base_model(input_shape, num_classes)\n",
        "        model_base.fit(x_train, y_train, epochs=EPOCHS, batch_size=64, validation_split=0.2,\n",
        "                       callbacks=[EarlyStopping(monitor='val_loss', patience=2)], verbose=1)\n",
        "        model_base.save(base_path)\n",
        "\n",
        "    num_params_base = model_base.count_params()\n",
        "\n",
        "    acc_base_fp32, time_base_fp32 = evaluate_model(model_base, x_test, y_test)\n",
        "\n",
        "    test_image = tf.convert_to_tensor(x_test[:1], dtype=tf.float32)\n",
        "    latency_base_fp32 = profile_workload(model_base, test_image)\n",
        "\n",
        "    def representative_data_gen():\n",
        "        for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(100):\n",
        "            yield [tf.cast(input_value, tf.float32)]\n",
        "\n",
        "    quantize_model_to_int8(model_base, representative_data_gen, int8_base_path)\n",
        "    quantize_model_to_fp16(model_base, fp16_base_path)\n",
        "\n",
        "    int8_base_size = get_file_size(int8_base_path)\n",
        "    fp16_base_size = get_file_size(fp16_base_path)\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=int8_base_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    acc_base_int8 = evaluate_tflite_accuracy(interpreter, x_test, y_test, quantized=True)\n",
        "    latency_base_int8 = profile_tflite_model(interpreter, np.round(x_test[:1] * 255).astype(np.int8))\n",
        "\n",
        "    interpreter = tf.lite.Interpreter(model_path=fp16_base_path)\n",
        "    interpreter.allocate_tensors()\n",
        "    acc_base_fp16 = evaluate_tflite_accuracy(interpreter, x_test, y_test, quantized=False)\n",
        "    latency_base_fp16 = profile_tflite_model(interpreter, x_test[:1].astype(np.float32))\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(f\"{'Metric':<30} {'Base Model':<20} {'Enhanced Model'}\")\n",
        "    print(f\"{'-'*80}\")\n",
        "    print(f\"{'Parameters':<30} {num_params_base:<20} {'deleted'}\")\n",
        "    print(f\"{'Accuracy FP32 (%)':<30} {acc_base_fp32*100:.2f}%{'':<12} {'deleted'}%\")\n",
        "    print(f\"{'Accuracy FP16 (%)':<30} {acc_base_fp16*100:.2f}%{'':<12} {'deleted'}%\")\n",
        "    print(f\"{'Accuracy INT8 (%)':<30} {acc_base_int8*100:.2f}%{'':<12} {'deleted'}%\")\n",
        "    print(f\"{'Latency FP32 (ms)':<30} {latency_base_fp32:.2f}{'':<14} {'deleted'}\")\n",
        "    print(f\"{'Latency FP16 (ms)':<30} {latency_base_fp16:.2f}{'':<14} {'deleted'}\")\n",
        "    print(f\"{'Latency INT8 (ms)':<30} {latency_base_int8:.2f}{'':<14} {'deleted'}\")\n",
        "    print(f\"{'Size FP32 (KB)':<30} {get_file_size(base_path):.2f}{'':<14} {'deleted'}\")\n",
        "    print(f\"{'Size FP16 (KB)':<30} {fp16_base_size:.2f}{'':<14} {'deleted'}\")\n",
        "    print(f\"{'Size INT8 (KB)':<30} {int8_base_size:.2f}{'':<14} {'deleted'}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TensorFlow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
