{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase-1 code starter template\n",
        "### The below code is for your reference; please feel free to change it partially or fully.\n",
        "### Please make sure it does not have any bugs or mistakes. Code authors DO NOT claim the code is bug-free. It is the student's responsibility to ensure its correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CP4ljRrIt4g",
        "outputId": "0e5cf3f9-9a65-4bc9-b121-226ebc8b5210"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def create_base_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(2, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def prepare_dataset(dataset_name):\n",
        "    if dataset_name == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        num_classes = 10\n",
        "        input_shape = (28, 28, 1)\n",
        "        x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "        x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    elif dataset_name == 'cifar10':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        num_classes = 10\n",
        "        input_shape = (32, 32, 3)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), input_shape, num_classes\n",
        "\n",
        "def evaluate_model(dataset_name, max_epoch, device):\n",
        "    (x_train, y_train), (x_test, y_test), input_shape, num_classes = prepare_dataset(dataset_name)\n",
        "\n",
        "    with tf.device(device):\n",
        "        model = create_base_model(input_shape, num_classes)\n",
        "        early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        start_time = time.time()\n",
        "        model.fit(x_train, y_train, epochs=max_epoch, batch_size=64, validation_split=0.2,\n",
        "                  callbacks=[early_stop], verbose=1)\n",
        "        train_time = time.time() - start_time\n",
        "\n",
        "        start_time = time.time()\n",
        "        test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "        eval_time = time.time() - start_time\n",
        "\n",
        "        num_param = model.count_params() # counting number of model's parameters\n",
        "        \n",
        "        print(f\"{dataset_name.upper()} Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "        print(f\"{dataset_name.upper()} Number of Parameters: {num_param}\")\n",
        "\n",
        "    return model, num_param, x_test, test_accuracy, train_time, eval_time\n",
        "\n",
        "def profile_workload(model, device, dev_name, image, iterations=30):\n",
        "    print(f\"Profiling on {dev_name}...\")\n",
        "    latencies = []\n",
        "    with tf.device(device):\n",
        "        for _ in tqdm(range(10), desc=\"Warm-up...\"):\n",
        "            start = time.time()\n",
        "            _ = model(image, training=False)\n",
        "        for _ in tqdm(range(iterations), desc=\"Profiling\"):\n",
        "            start = time.time()\n",
        "            _ = model(image, training=False)\n",
        "            latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "    avg_latency = np.mean(latencies)\n",
        "    print(f\"Average Latency on {dev_name}: {avg_latency:.2f} ms\")\n",
        "\n",
        "    prediction = model(image, training=False)\n",
        "    predicted_class = tf.argmax(prediction, axis=1).numpy()[0]\n",
        "    print(f\"Predicted Class: {predicted_class}\")\n",
        "    return avg_latency\n",
        "\n",
        "# Device priority: CUDA > MPS > CPU\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    device = '/GPU:0'\n",
        "    dev_name = 'GPU'\n",
        "elif tf.config.list_physical_devices('MPS'):\n",
        "    device = '/MPS:0'\n",
        "    dev_name = 'Apple MPS'\n",
        "else:\n",
        "    device = '/CPU:0'\n",
        "    dev_name = 'CPU'\n",
        "print(f'using {dev_name}')\n",
        "datasets = ['fashion_mnist', 'cifar10']\n",
        "for dataset in datasets:\n",
        "    print(f\"\\nProcessing {dataset}...\")\n",
        "    model, num_param, x_test, acc, train_t, eval_t = evaluate_model(dataset, max_epoch=25, device=device)\n",
        "    test_image = tf.convert_to_tensor(x_test[:1], dtype=tf.float32)\n",
        "    profile_workload(model, device, dev_name, test_image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Phase-3 code starter template\n",
        "### The below code is for your reference; please feel free to change it partially or fully.\n",
        "### Please make sure it does not have any bugs or mistakes. Code authors DO NOT claim the code is bug-free. It is the student's responsibility to ensure its correctness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.datasets import fashion_mnist, cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "assert tf.__version__=='2.15.0', 'WARNING!!! different TensorFlow version may produce an error while quantizing.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_base_model(input_shape, num_classes):\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(16, (3, 3), activation='relu', input_shape=input_shape),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(2, activation='relu'),\n",
        "        layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def prepare_dataset(dataset_name):\n",
        "    if dataset_name == 'fashion_mnist':\n",
        "        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "        num_classes = 10\n",
        "        input_shape = (28, 28, 1)\n",
        "        x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "        x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "    elif dataset_name == 'cifar10':\n",
        "        (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "        num_classes = 10\n",
        "        input_shape = (32, 32, 3)\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported dataset: {dataset_name}\")\n",
        "\n",
        "    x_train = x_train.astype('float32') / 255\n",
        "    x_test = x_test.astype('float32') / 255\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    return (x_train, y_train), (x_test, y_test), input_shape, num_classes\n",
        "\n",
        "def evaluate_model(model, x_test, y_test, device):\n",
        "    with tf.device(device):\n",
        "        start_time = time.time()\n",
        "        loss, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "        eval_time = time.time() - start_time\n",
        "    return acc, eval_time\n",
        "\n",
        "def profile_workload(model, device, dev_name, image, iterations=30):\n",
        "    print(f\"Profiling on {dev_name}...\")\n",
        "    latencies = []\n",
        "    with tf.device(device):\n",
        "        for _ in tqdm(range(10), desc=\"Warm-up\"):\n",
        "            _ = model(image, training=False)\n",
        "        for _ in tqdm(range(iterations), desc=\"Profiling\"):\n",
        "            start = time.time()\n",
        "            _ = model(image, training=False)\n",
        "            latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "    avg_latency = np.mean(latencies)\n",
        "    print(f\"Average Latency on {dev_name}: {avg_latency:.2f} ms\")\n",
        "    return avg_latency\n",
        "\n",
        "def profile_tflite_model(interpreter, input_tensor, iterations=30):\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    latencies = []\n",
        "\n",
        "    for _ in range(10):\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "        interpreter.invoke()\n",
        "\n",
        "    for _ in range(iterations):\n",
        "        start = time.time()\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_tensor)\n",
        "        interpreter.invoke()\n",
        "        latencies.append((time.time() - start) * 1000)\n",
        "\n",
        "    avg_latency = np.mean(latencies)\n",
        "    return avg_latency\n",
        "\n",
        "def quantize_model_to_int8(model, representative_data_gen, save_path=\"model_int8.tflite\"):\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.representative_dataset = representative_data_gen\n",
        "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "    converter.inference_input_type = tf.int8\n",
        "    converter.inference_output_type = tf.int8\n",
        "\n",
        "    tflite_quant_model = converter.convert()\n",
        "    with open(save_path, \"wb\") as f:\n",
        "        f.write(tflite_quant_model)\n",
        "\n",
        "    print(f\"INT8 Quantized model saved at {save_path}\")\n",
        "\n",
        "def get_file_size(file_path):\n",
        "    return os.path.getsize(file_path) / 1024  # KB\n",
        "\n",
        "def evaluate_tflite_accuracy(tflite_model_path, x_test, y_test):\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    correct = 0\n",
        "    total = x_test.shape[0]\n",
        "    for i in range(total):\n",
        "        input_data = np.round(x_test[i:i+1] * 255).astype(np.int8)  # <- FIXED\n",
        "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "        interpreter.invoke()\n",
        "        output = interpreter.get_tensor(output_details[0]['index'])\n",
        "        if np.argmax(output) == np.argmax(y_test[i]):\n",
        "            correct += 1\n",
        "    accuracy = correct / total\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "# -------------------\n",
        "# Main Code\n",
        "# -------------------\n",
        "if tf.config.list_physical_devices('GPU'):\n",
        "    device = '/GPU:0'\n",
        "    dev_name = 'GPU'\n",
        "elif tf.config.list_physical_devices('MPS'):\n",
        "    device = '/MPS:0'\n",
        "    dev_name = 'Apple MPS'\n",
        "else:\n",
        "    device = '/CPU:0'\n",
        "    dev_name = 'CPU'\n",
        "print(f'Using {dev_name}')\n",
        "\n",
        "datasets = ['fashion_mnist', 'cifar10']\n",
        "\n",
        "for dataset in datasets:\n",
        "    print(f\"\\nProcessing {dataset}...\")\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test), input_shape, num_classes = prepare_dataset(dataset)\n",
        "\n",
        "    with tf.device(device):\n",
        "        model = create_base_model(input_shape, num_classes)\n",
        "\n",
        "        early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "        start_train = time.time()\n",
        "        model.fit(x_train, y_train, epochs=25, batch_size=64, validation_split=0.2,\n",
        "                  callbacks=[early_stop], verbose=1)\n",
        "        train_time = time.time() - start_train\n",
        "\n",
        "        test_acc_fp32, eval_time_fp32 = evaluate_model(model, x_test, y_test, device)\n",
        "        num_params = model.count_params()\n",
        "\n",
        "    test_image = tf.convert_to_tensor(x_test[:1], dtype=tf.float32)\n",
        "    orig_latency = profile_workload(model, device, dev_name, test_image)\n",
        "\n",
        "    # Save original model\n",
        "    model.save('model_fp32.h5')\n",
        "    fp32_size = get_file_size('model_fp32.h5')\n",
        "    print(f\"Original Model Size: {fp32_size:.2f} KB\")\n",
        "\n",
        "    # Quantization\n",
        "    def representative_data_gen():\n",
        "        for input_value in tf.data.Dataset.from_tensor_slices(x_test).batch(1).take(100):\n",
        "            yield [tf.cast(input_value * 255.0, tf.float32)]\n",
        "\n",
        "    quantize_model_to_int8(model, representative_data_gen, save_path=\"model_int8.tflite\")\n",
        "    int8_size = get_file_size(\"model_int8.tflite\")\n",
        "    print(f\"Quantized Model Size: {int8_size:.2f} KB\")\n",
        "\n",
        "    # Accuracy after quantization\n",
        "    test_acc_int8 = evaluate_tflite_accuracy(\"model_int8.tflite\", x_test, y_test)\n",
        "\n",
        "    # Inference latency after quantization\n",
        "    interpreter = tf.lite.Interpreter(model_path=\"model_int8.tflite\")\n",
        "    interpreter.allocate_tensors()\n",
        "    input_details = interpreter.get_input_details()\n",
        "    test_image_int8 = np.round(x_test[:1] * 255).astype(np.int8)\n",
        "    int8_latency = profile_tflite_model(interpreter, test_image_int8)\n",
        "\n",
        "    print(\"\\nSummary:\")\n",
        "    print(f\"{'Metric':<25} {'Before Quantization':<20} {'After Quantization'}\")\n",
        "    print(f\"{'-'*70}\")\n",
        "    print(f\"{'Number of Parameters':<25} {num_params:<20} {num_params}\")\n",
        "    print(f\"{'Test Accuracy (%)':<25} {test_acc_fp32*100:.2f}%{'':<12} {test_acc_int8*100:.2f}%\")\n",
        "    print(f\"{'Training Time (s)':<25} {train_time:.2f}{'':<16} {'-'}\")\n",
        "    print(f\"{'Evaluation Time (s)':<25} {eval_time_fp32:.4f}{'':<14} {'-'}\")\n",
        "    print(f\"{'Inference Latency (ms)':<25} {orig_latency:.2f}{'':<14} {int8_latency:.2f}\")\n",
        "    print(f\"{'Model Size (KB)':<25} {fp32_size:.2f}{'':<14} {int8_size:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "TensorFlow",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.21"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
